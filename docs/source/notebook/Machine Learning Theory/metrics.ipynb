{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f637c2",
   "metadata": {},
   "source": [
    "# *Introduction to few key NLP metrics*\n",
    "\n",
    "In any scenario, where there is a need to judge how good a machine translation of a given source language is, or judge the performance of a classifier, we need to introduce metrics. Note that, in case of machine translation source and target language can be anything--a PDF, latex code corresponding to a PDF, any human language, etc. Hence these metrics are language-independent. We attempt to introduce few of these metrics here:\n",
    "\n",
    "+ Levenshtein distance (Edit distance)\n",
    "+ BLEU (BiLingual Evaluation Understudy)\n",
    "+ ROUGE (Todo)\n",
    "+ METEOR (Todo)\n",
    "+ Precision\n",
    "+ Accuracy\n",
    "+ Recall\n",
    "+ F1 Score\n",
    "\n",
    "## Machine Translations related\n",
    "\n",
    "### Levenshtein distance\n",
    " Levenshtein or Edit distance is a fundamental string metric. Given two strings $A$ and $B$, it computes minimum number of insertions, deletions or replacements needed to transform $A$ to $B$. It helps to compute how much different a machine translated string is from the source string. Edit distance has a convenient recursive formula:\n",
    " \n",
    " $$lev_{a,b}(i,j) = \\begin{cases} \n",
    "          lev_{a,b}(i+1,j+1) & if \\ a[i]=b[j], a,b\\neq\\phi \\\\\n",
    "          1+min\\{lev_{a,b}(i,j+1),lev_{a,b}(i+1,j),lev_{a,b}(i+1,j+1)\\} & if \\ a[i] \\neq b[j], a,b\\neq \\phi \\\\\n",
    "          |a[i:]| & if \\ b=\\phi \\\\\n",
    "          |b[j:]| & if \\ b\\neq\\phi, a=\\phi\n",
    "       \\end{cases}$$\n",
    "       \n",
    "where <mark>$lev_{a,b}(i,j)$ is the levenshtein distance of the string $a$ starting from $i^{th}$ index w.r.t. string $b$ starting from $j^{th}$ index</mark>. \n",
    "\n",
    "*EXPLANATION*: In order to compute $lev_{a,b}(i,j)$:\n",
    "+ If $a[i] = b[j]$, then it is quite clear that we recursively compute the Edit distance of the string $a[i+1:]$ w.r.t. $b[j+1:]\n",
    " $\n",
    "+ If $a[i] \\neq b[j]$, then either:\n",
    "  + we add $b[j]$ in the current position of $a$, so we recursively compute the Edit distance of the string $a[i:]$ w.r.t. $b[j+1:]$ (as $b[j]$ has been matched but didn't exhaust any character of the original $a$) and add $1$ to result(for the $Add$ operation).\n",
    "  + we replace $a[i]$ with $b[j]$, so we recursively compute the Edit distance of the string $a[i+1:]$ w.r.t. $b[j+1:]$ (since $b[j]$ has been matched, and exhausted one more character of $a$) and add $1$ to result(for the $Replace$ operation).\n",
    "  + we delete $a[i]$ in hope that the rest of the $a$ string matches with rest of the $b$ string, so we recursively compute Edit distance of $a[i+1:]$ w.r.t. $b[j]$(since character of $a$ has been exhausted without matching $b[j]$)\n",
    " \n",
    "The recursive formula, naturally leads to a bottom up dynamic programming approach, where we take a $(|a|+1)$x$(|b|+1)$ matrix $dp$ with rows indexed by $a$ and column by $b$ such that (we output $dp[0][0]=lev_{a,b}(0,0)$ at the end):\n",
    "$$ dp[i][j] =\\begin{cases}\n",
    "lev_{a,b}(i,j) & if \\ 0\\leq i\\leq|a|, 0\\leq j\\leq|b|\\\\\n",
    "lev_{a,\\phi}(i,j) & if \\ j=|b| \\\\\n",
    "leb_{\\phi,b}(i,j) & if \\ i=|a|\\\\\n",
    "\\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce0e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs in O(len(str1)*len(str2))\n",
    "def levenshtein( str1, str2):\n",
    "    l1 = len(str1)\n",
    "    l2 = len(str2)\n",
    "    matrix = [[-1]*(l2+1) for i in range(0,l1+1)] # initialisation of the (len(str1)+1)x(len(str2)+1) matrix with -1(s)\n",
    "    \n",
    "    # base cases\n",
    "    for i in range(l2+1):\n",
    "        matrix[l1][i] = l2 - i # initialisation of the bottom row\n",
    "    \n",
    "    for j in range(l1+1):\n",
    "        matrix[j][l2] = l1 - j # initialisation of the rightmost column\n",
    "        \n",
    "    # computation starts!\n",
    "    for i in range(l1-1,-1,-1): # bottom-up fashion--- from second last row to top row, and in each row from second-last cell to starting cell\n",
    "        for j in range(l2-1,-1,-1):\n",
    "            if str1[i]==str2[j]:\n",
    "                matrix[i][j] = matrix[i+1][j+1] # if the characters are equal, move both pointers\n",
    "            else:\n",
    "                matrix[i][j] = 1 + min(matrix[i+1][j],matrix[i+1][j+1], matrix[i][j+1]) # else, add 1 (pertaining to either insert, replace or delete) to the minimum of the levenshstein distances of the remaining pieces of the strings\n",
    "            \n",
    "    \n",
    "    return matrix[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b193c0",
   "metadata": {},
   "source": [
    "Examples:\n",
    "+ levenshtein distance of *\"abc\"* w.r.t *\"adc\"* is $1$ : *\"abc\"*  $\\xrightarrow[]{\\text{replace \"b\" with \"d\"}}$ *\"adc\"*\n",
    "+ levenshtein distance of *\"horse\"* w.r.t. *\"ros\"* is $3$ : *\"horse\"* $\\xrightarrow[]{\\text{replace \"h\" with \"r\"}}$ *\"rorse\"* $\\xrightarrow[]{\\text{delete \"r\"}}$ *\"rose\"* $\\xrightarrow[]{\\text{delete \"e\"}}$ *\"ros\"* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9f4f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(levenshtein(\"abc\", \"adc\"))\n",
    "print(levenshtein(\"horse\",\"ros\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dc4e9b",
   "metadata": {},
   "source": [
    "### BLEU metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c4b61",
   "metadata": {},
   "source": [
    "<mark>Definition 1 (*$n-gram$*)</mark>: Generally an $n-gram$ is a sequence of $n$ consecutive words, letters, syllables or base pairs (*for machine translation(MT) purposes they are generally words*) collected from a text corpus(dataset).\n",
    "\n",
    "Ex: bigrams($2$-grams) of *\"This article is on NLP\"* are *\"This article\"*, *\"article is\"*, *\"on NLP\"*, etc. \n",
    "\n",
    "Given an Machine Translation of a source \"sentence\", and one or more \"references\", we need to able to say how close the translaton is w.r.t the references and clearly distinguish a good candidate from a bad one.\n",
    "\n",
    "<mark>Definition 2(*modified $n-gram$ precision*)</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f78c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
